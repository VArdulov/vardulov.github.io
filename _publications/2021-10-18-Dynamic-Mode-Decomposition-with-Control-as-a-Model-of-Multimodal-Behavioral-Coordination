---
title: "Dynamic Mode Decomposition with Control as a Model of Multimodal Behavioral Coordination"
collection: publications
permalink: /publication/2021-10-18-Dynamic-Mode-Decomposition-with-Control-as-a-Model-of-Multimodal-Behavioral-Coordination
excerpt: 'Using a linear dynamical system model to identify behaviors correlated with social coordination between infants and their mothers'
date: 2021-10-18
venue: 'International Conference on Multimodal Interaction 2021'
paperurl: 'https://dl.acm.org/doi/abs/10.1145/3462244.3479916'
citation: 'Klein, L., Ardulov, V., Gharib, A., Thompson, B., Levitt, P., & Matarić, M. (2021, October). Dynamic Mode Decomposition with Control as a Model of Multimodal Behavioral Coordination. In Proceedings of the 2021 International Conference on Multimodal Interaction (pp. 25-33).'
---
**Abstract**:Observing how infants and mothers coordinate their behaviors can highlight meaningful patterns in early communication and infant development. While dyads often differ in the modalities they use to communicate, especially in the first year of life, it remains unclear how to capture coordination across multiple types of behaviors using existing computational models of interpersonal synchrony. This paper explores Dynamic Mode Decomposition with control (DMDc) as a method of integrating multiple signals from each communicating partner into a model of multimodal behavioral coordination. We used an existing video dataset to track the head pose, arm pose, and vocal fundamental frequency of infants and mothers during the Face-to-Face Still-Face (FFSF) procedure, a validated 3-stage interaction paradigm. For each recorded interaction, we fit both unimodal and multimodal DMDc models to the extracted pose data. The resulting dynamic characteristics of the models were analyzed to evaluate trends in individual behaviors and dyadic processes across infant age and stages of the interactions. Results demonstrate that observed trends in interaction dynamics across stages of the FFSF protocol were stronger and more significant when models incorporated both head and arm pose data, rather than a single behavior modality. Model output showed significant trends across age, identifying changes in infant movement and in the relationship between infant and mother behaviors. Models that included mothers’ audio data demonstrated similar results to those evaluated with pose data, confirming that DMDc can leverage different sets of behavioral signals from each interacting partner. Taken together, our results demonstrate the potential of DMDc toward integrating multiple behavioral signals into the measurement of multimodal interpersonal coordination.
[<i>Published in Proceeding of ICMI 2021</i>](https://dl.acm.org/doi/abs/10.1145/3462244.3479916)
